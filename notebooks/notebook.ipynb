{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Детекция переломов на рентген‑снимках: подготовка данных и обучение\n",
    "\n",
    "Этот ноутбук фиксирует ключевые шаги проекта: подготовку данных, объединение классов, конвертацию YOLO‑разметки в COCO,\n",
    "обучение Faster R‑CNN в Detectron2 и базовое обучение YOLO.\n",
    "Это копия моего kaggle ноутбука с исправлениями от нейронки(комментарии)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Установка зависимостей (опционально)\n",
    "\n",
    "Если запускаете в чистом окружении, установите зависимости. В проекте используются: torch/torchvision, detectron2, ultralytics, pycocotools.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Если нужно — установите зависимости (можно запускать по одной строке)\n",
    "# !pip install -r requirements.txt\n",
    "# !python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Импорты и версии\n",
    "\n",
    "Проверяем, что основные библиотеки доступны и видим их версии.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "try:\n",
    "    import detectron2\n",
    "    detectron2_version = detectron2.__version__\n",
    "except Exception as exc:\n",
    "    detectron2_version = f\"not available ({exc})\"\n",
    "\n",
    "try:\n",
    "    from ultralytics import YOLO\n",
    "    ultralytics_ok = True\n",
    "except Exception as exc:\n",
    "    YOLO = None\n",
    "    ultralytics_ok = False\n",
    "    ultralytics_error = exc\n",
    "\n",
    "print(\"torch:\", torch.__version__, \"cuda:\", torch.cuda.is_available())\n",
    "print(\"detectron2:\", detectron2_version)\n",
    "print(\"ultralytics:\", \"ok\" if ultralytics_ok else f\"not available ({ultralytics_error})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Пути к данным\n",
    "\n",
    "Ожидаем структуру данных как в оригинальном датасете YOLO: `train/valid/test` + `images/labels`.\n",
    "Данные не хранятся в репозитории — скачиваются отдельно и кладутся в `data/BoneFractureYolo8`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_ROOT = Path(\"data/BoneFractureYolo8\")\n",
    "\n",
    "TRAIN_IMG = DATA_ROOT / \"train\" / \"images\"\n",
    "TRAIN_LBL = DATA_ROOT / \"train\" / \"labels\"\n",
    "\n",
    "VAL_IMG = DATA_ROOT / \"valid\" / \"images\"\n",
    "VAL_LBL = DATA_ROOT / \"valid\" / \"labels\"\n",
    "\n",
    "TEST_IMG = DATA_ROOT / \"test\" / \"images\"\n",
    "TEST_LBL = DATA_ROOT / \"test\" / \"labels\"\n",
    "\n",
    "# JSON‑файлы после конвертации в COCO (для Detectron2 и метрик)\n",
    "TRAIN_JSON = DATA_ROOT / \"train_merged.json\"\n",
    "VAL_JSON = DATA_ROOT / \"val_merged.json\"\n",
    "TEST_JSON = DATA_ROOT / \"test_merged.json\"\n",
    "\n",
    "# Оригинальный data.yaml для YOLO (7 классов)\n",
    "DATA_YAML = DATA_ROOT / \"data.yaml\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Классы и объединение\n",
    "\n",
    "В исходной разметке 7 классов. Класс **humerus fracture** содержит всего 3 объекта,\n",
    "поэтому он объединён с **humerus**. Итоговый протокол — 6 классов.\n",
    "\n",
    "Также в данных присутствуют изображения без переломов, и они использовались при обучении.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old ids: 0..6\n",
    "OLD_NAMES = [\n",
    "    \"elbow positive\",\n",
    "    \"fingers positive\",\n",
    "    \"forearm fracture\",\n",
    "    \"humerus fracture\",\n",
    "    \"humerus\",\n",
    "    \"shoulder fracture\",\n",
    "    \"wrist positive\",\n",
    "]\n",
    "\n",
    "# merge old 3 -> old 4\n",
    "MERGE_FROM_OLD = 3\n",
    "MERGE_TO_OLD = 4\n",
    "\n",
    "# keep these old ids after merge\n",
    "KEPT_OLD_IDS = [0, 1, 2, 4, 5, 6]\n",
    "OLD_TO_NEW = {old_id: new_id for new_id, old_id in enumerate(KEPT_OLD_IDS)}\n",
    "\n",
    "NEW_NAMES = [\n",
    "    \"elbow positive\",\n",
    "    \"fingers positive\",\n",
    "    \"forearm fracture\",\n",
    "    \"humerus\",\n",
    "    \"shoulder fracture\",\n",
    "    \"wrist positive\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Краткий анализ разметки (YOLO‑сегментации)\n",
    "\n",
    "Считаем количество объектов по классам и долю пустых изображений (без разметки).\n",
    "Это помогает принять решения по объединению классов и параметрам детекции.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def scan_yolo_seg_labels(labels_dir: Path, num_classes: int):\n",
    "    labels_dir = Path(labels_dir)\n",
    "    txts = sorted(labels_dir.rglob(\"*.txt\"))\n",
    "\n",
    "    inst_per_class = Counter()\n",
    "    imgs_with_class = Counter()\n",
    "    empty_images = 0\n",
    "\n",
    "    areas_by_class = defaultdict(list)\n",
    "    wh_by_class = defaultdict(list)\n",
    "\n",
    "    for txt in txts:\n",
    "        lines = [l.strip() for l in txt.read_text().splitlines() if l.strip()]\n",
    "        if not lines:\n",
    "            empty_images += 1\n",
    "            continue\n",
    "\n",
    "        present = set()\n",
    "\n",
    "        for line in lines:\n",
    "            parts = line.split()\n",
    "            if len(parts) < 7:\n",
    "                continue\n",
    "\n",
    "            cls = int(float(parts[0]))\n",
    "            if not (0 <= cls < num_classes):\n",
    "                continue\n",
    "\n",
    "            coords = list(map(float, parts[1:]))\n",
    "            if len(coords) % 2 != 0:\n",
    "                continue\n",
    "\n",
    "            xs = np.array(coords[0::2], dtype=np.float32)\n",
    "            ys = np.array(coords[1::2], dtype=np.float32)\n",
    "\n",
    "            xmin, xmax = float(xs.min()), float(xs.max())\n",
    "            ymin, ymax = float(ys.min()), float(ys.max())\n",
    "            w = max(0.0, xmax - xmin)\n",
    "            h = max(0.0, ymax - ymin)\n",
    "            area = w * h\n",
    "\n",
    "            inst_per_class[cls] += 1\n",
    "            present.add(cls)\n",
    "\n",
    "            wh_by_class[cls].append((w, h))\n",
    "            areas_by_class[cls].append(area)\n",
    "\n",
    "        for c in present:\n",
    "            imgs_with_class[c] += 1\n",
    "\n",
    "    total_images = len(txts)\n",
    "\n",
    "    print(f\"Всего label‑файлов (≈ изображений): {total_images}\")\n",
    "    print(f\"Пустых (нет разметки): {empty_images}  ({empty_images/total_images:.1%})\n",
    "\")\n",
    "\n",
    "    print(\"Объектов (instances) по классам:\")\n",
    "    for c in range(num_classes):\n",
    "        print(f\"  class {c}: {inst_per_class[c]}\")\n",
    "\n",
    "    print(\"\n",
    "Изображений, где встречается класс:\")\n",
    "    for c in range(num_classes):\n",
    "        print(f\"  class {c}: {imgs_with_class[c]}  ({imgs_with_class[c]/total_images:.1%})\")\n",
    "\n",
    "    print(\"\n",
    "Размеры bbox (нормализованные), медианы по классам:\")\n",
    "    for c in range(num_classes):\n",
    "        if len(wh_by_class[c]) == 0:\n",
    "            print(f\"  class {c}: нет объектов\")\n",
    "            continue\n",
    "        ws = np.array([x[0] for x in wh_by_class[c]])\n",
    "        hs = np.array([x[1] for x in wh_by_class[c]])\n",
    "        ars = np.array(areas_by_class[c])\n",
    "        print(\n",
    "            f\"  class {c}: median w={np.median(ws):.4f}, \"\n",
    "            f\"h={np.median(hs):.4f}, area={np.median(ars):.6f}\"\n",
    "        )\n",
    "\n",
    "\n",
    "scan_yolo_seg_labels(labels_dir=TRAIN_LBL, num_classes=7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Конвертация YOLO‑сегментаций → COCO (bbox) с объединением классов\n",
    "\n",
    "Конвертация нужна для Detectron2 и для сравнимых метрик.\n",
    "Выходные файлы: `train_merged.json`, `val_merged.json`, `test_merged.json`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def yolo_seg_to_coco_merged(images_dir: Path, labels_dir: Path, out_json: Path):\n",
    "    images_dir = Path(images_dir)\n",
    "    labels_dir = Path(labels_dir)\n",
    "\n",
    "    coco = {\n",
    "        \"images\": [],\n",
    "        \"annotations\": [],\n",
    "        \"categories\": [{\"id\": i, \"name\": n} for i, n in enumerate(NEW_NAMES)],\n",
    "    }\n",
    "\n",
    "    ann_id = 1\n",
    "    img_id = 1\n",
    "\n",
    "    img_paths = []\n",
    "    for ext in (\"*.png\", \"*.jpg\", \"*.jpeg\", \"*.bmp\", \"*.tif\", \"*.tiff\"):\n",
    "        img_paths += list(images_dir.rglob(ext))\n",
    "    img_paths = sorted(img_paths)\n",
    "\n",
    "    bad_class_lines = 0\n",
    "\n",
    "    for img_path in img_paths:\n",
    "        with Image.open(img_path) as im:\n",
    "            w, h = im.size\n",
    "\n",
    "        coco[\"images\"].append({\n",
    "            \"id\": img_id,\n",
    "            \"file_name\": str(img_path.relative_to(images_dir)),\n",
    "            \"width\": w,\n",
    "            \"height\": h,\n",
    "        })\n",
    "\n",
    "        label_path = labels_dir / (img_path.stem + \".txt\")\n",
    "        lines = []\n",
    "        if label_path.exists():\n",
    "            lines = [l.strip() for l in label_path.read_text().splitlines() if l.strip()]\n",
    "\n",
    "        for line in lines:\n",
    "            parts = line.split()\n",
    "            if len(parts) < 1 + 6:\n",
    "                continue\n",
    "\n",
    "            cls_old = int(float(parts[0]))\n",
    "            if not (0 <= cls_old < len(OLD_NAMES)):\n",
    "                bad_class_lines += 1\n",
    "                continue\n",
    "\n",
    "            # merge 3 -> 4\n",
    "            if cls_old == MERGE_FROM_OLD:\n",
    "                cls_old = MERGE_TO_OLD\n",
    "\n",
    "            # пропускаем удалённый класс\n",
    "            if cls_old not in OLD_TO_NEW:\n",
    "                continue\n",
    "\n",
    "            cls_new = OLD_TO_NEW[cls_old]\n",
    "\n",
    "            coords = list(map(float, parts[1:]))\n",
    "            if len(coords) % 2 != 0:\n",
    "                continue\n",
    "\n",
    "            xs = coords[0::2]\n",
    "            ys = coords[1::2]\n",
    "\n",
    "            xs_px = [max(0.0, min(w - 1.0, x * w)) for x in xs]\n",
    "            ys_px = [max(0.0, min(h - 1.0, y * h)) for y in ys]\n",
    "\n",
    "            xmin, xmax = min(xs_px), max(xs_px)\n",
    "            ymin, ymax = min(ys_px), max(ys_px)\n",
    "\n",
    "            bw = max(1.0, xmax - xmin)\n",
    "            bh = max(1.0, ymax - ymin)\n",
    "\n",
    "            bbox = [float(xmin), float(ymin), float(bw), float(bh)]\n",
    "\n",
    "            poly = []\n",
    "            for x, y in zip(xs_px, ys_px):\n",
    "                poly += [float(x), float(y)]\n",
    "            seg = [poly] if len(poly) >= 6 else []\n",
    "\n",
    "            coco[\"annotations\"].append({\n",
    "                \"id\": ann_id,\n",
    "                \"image_id\": img_id,\n",
    "                \"category_id\": cls_new,\n",
    "                \"bbox\": bbox,\n",
    "                \"area\": float(bw * bh),\n",
    "                \"iscrowd\": 0,\n",
    "                \"segmentation\": seg,\n",
    "            })\n",
    "            ann_id += 1\n",
    "\n",
    "        img_id += 1\n",
    "\n",
    "    out_json = Path(out_json)\n",
    "    out_json.parent.mkdir(parents=True, exist_ok=True)\n",
    "    out_json.write_text(json.dumps(coco, ensure_ascii=False))\n",
    "\n",
    "    print(f\"Saved {out_json}: images={len(coco['images'])}, anns={len(coco['annotations'])}\")\n",
    "    if bad_class_lines:\n",
    "        print(f\"WARNING: skipped {bad_class_lines} label lines with class_id outside [0..6]\")\n",
    "\n",
    "\n",
    "yolo_seg_to_coco_merged(TRAIN_IMG, TRAIN_LBL, TRAIN_JSON)\n",
    "yolo_seg_to_coco_merged(VAL_IMG, VAL_LBL, VAL_JSON)\n",
    "yolo_seg_to_coco_merged(TEST_IMG, TEST_LBL, TEST_JSON)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Регистрация датасетов в Detectron2\n",
    "\n",
    "Регистрируем COCO‑json и фиксируем классы в metadata.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.data import MetadataCatalog\n",
    "\n",
    "register_coco_instances(\"fracture_train_merged\", {}, str(TRAIN_JSON), str(TRAIN_IMG))\n",
    "register_coco_instances(\"fracture_val_merged\", {}, str(VAL_JSON), str(VAL_IMG))\n",
    "\n",
    "MetadataCatalog.get(\"fracture_train_merged\").thing_classes = NEW_NAMES\n",
    "MetadataCatalog.get(\"fracture_val_merged\").thing_classes = NEW_NAMES\n",
    "\n",
    "print(\"Registered merged datasets with classes:\", NEW_NAMES)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Обучение Faster R‑CNN (Detectron2)\n",
    "\n",
    "Базовый конфиг R50‑FPN. Ключевые параметры: `NUM_CLASSES=6`, `imgsz=1024`, `FILTER_EMPTY_ANNOTATIONS=False`,\n",
    "расширенные `aspect ratios` для вытянутых боксов.\n",
    "\n",
    "Данные уже содержат аугментации (поворот, яркость/контраст). Дополнительные аугментации заметного улучшения не дали.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "import os\n",
    "\n",
    "\n",
    "class Trainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        return COCOEvaluator(dataset_name, cfg, False, output_folder)\n",
    "\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")\n",
    "\n",
    "cfg.DATASETS.TRAIN = (\"fracture_train_merged\",)\n",
    "cfg.DATASETS.TEST = (\"fracture_val_merged\",)\n",
    "\n",
    "cfg.DATALOADER.FILTER_EMPTY_ANNOTATIONS = False\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 6\n",
    "\n",
    "\n",
    "cfg.INPUT.MIN_SIZE_TRAIN = (1024,)\n",
    "cfg.INPUT.MAX_SIZE_TRAIN = 1024\n",
    "cfg.INPUT.MIN_SIZE_TEST = 1024\n",
    "cfg.INPUT.MAX_SIZE_TEST = 1024\n",
    "\n",
    "cfg.MODEL.ANCHOR_GENERATOR.ASPECT_RATIOS = [[0.33, 0.5, 1.0, 2.0, 3.0]] * 5\n",
    "cfg.TEST.DETECTIONS_PER_IMAGE = 300\n",
    "\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.0025\n",
    "cfg.SOLVER.WARMUP_ITERS = 500\n",
    "cfg.SOLVER.MAX_ITER = 15000\n",
    "cfg.SOLVER.STEPS = (10000, 13000)\n",
    "cfg.SOLVER.GAMMA = 0.1\n",
    "\n",
    "cfg.OUTPUT_DIR = str(DATA_ROOT / \"frcnn_r50_baseline\")\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "trainer = Trainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Визуализация предсказаний Faster R‑CNN\n",
    "\n",
    "Проверка качества боксов на валидации.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "\n",
    "cfg.MODEL.WEIGHTS = str(Path(cfg.OUTPUT_DIR) / \"model_final.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.3\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "dataset_dicts = DatasetCatalog.get(\"fracture_val_merged\")\n",
    "metadata = MetadataCatalog.get(\"fracture_val_merged\")\n",
    "\n",
    "for d in random.sample(dataset_dicts, k=min(6, len(dataset_dicts))):\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    outputs = predictor(img)\n",
    "    v = Visualizer(img[:, :, ::-1], metadata=metadata, scale=1.0)\n",
    "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(out.get_image())\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Обучение YOLO\n",
    "\n",
    "YOLO обучается на оригинальном датасете (7 классов) по `data.yaml`.\n",
    "Использовались параметры `epochs=50` и `imgsz=640`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if YOLO is None:\n",
    "    raise RuntimeError(\"Ultralytics не установлен\")\n",
    "\n",
    "model = YOLO(\"yolo26m.pt\")\n",
    "model.train(data=str(DATA_YAML), epochs=50, imgsz=640, device=[0, 1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
